{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2 - Reti neurali convolutive in TF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prerequisiti per il tutorial:**\n",
    "* [T1 - Reti neurali feedforward](1-Reti-neurali-feedforward.ipynb)\n",
    "\n",
    "**Contenuti del tutorial:**\n",
    "1. Concetti base delle reti neurali convolutive.\n",
    "2. Implementazione di una rete neurale convolutiva in TF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduzione alle reti convolutive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'enorme flessibilità delle reti neurali è allo stesso tempo il loro punto di forza ed il loro svantaggio. Consideriamo un problema dove l'input alla rete neurale è un'immagine di 64x64 pixel, in RGB, ad esempio una piccola telecamera che deve imparare a riconoscere la presenza o meno di una determinata persona. Nonostante si tratti di un'immagine molto piccola, in tutto avremmo già 64x64x3 = **12228 input** alla rete neurale, considerando che ciascun pixel è descritto da tre colori diversi. Con soli 10 neuroni nel primo strato nascosto, avremmo oltre **120mila parametri** liberi da adattare per riconoscere un qualche oggetto nell'immagine.\n",
    "\n",
    "Le **reti neurali convolutive** (convolutional neural network, CNN) sono un modo di risolvere questo problema quando, come nel caso delle immagini, l'input alla rete neurale presenta una forma di *località* dell'informazione. In questo caso, ciascun neurone nello strato nascosto viene sostituito da un filtro di dimensioni fisse (es., 5x5x3), che viene fatto scorrere sull'intera immagine per ottenere la sua uscita:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Esempio di filtro convolutivo](./images/Convolution_schematic.gif)\n",
    "http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uno **strato convolutivo** si ottiene facendo scorrere in parallelo diversi filtri di questo tipo sull'immagine, a cui viene fatta seguire una nonlinearità come in una rete neurale tradizionale. \n",
    "\n",
    "Considerando di nuovo il caso dell'immagine di prima, con 10 filtri di questo tipo si otterrebbero 5x5x3x10 = **750 parametri adattabili**, una riduzione di oltre 100 volte. Questa architettura è enormemente popolare per le immagini, ed ha trovato applicazioni di recente anche per l'[audio](https://deepmind.com/blog/wavenet-generative-model-raw-audio/) e problemi di [processamento del linguaggio](http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/); entrambi situazioni dove le convoluzioni, a differenza che nella figura sopra, sono mono-dimensionali.\n",
    "\n",
    "In pratica, una CNN si costruisce interponendo a questi strati convolutivi altri strati, come nella figura sotto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Esempio di rete convolutiva](https://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/11/Screen-Shot-2015-11-07-at-7.26.20-AM.png)\n",
    "http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gli strati di **pooling** servono ad effettuare un sottocampionamento dell'uscita dello strato precedente, ad esempio prendendo il massimo valore in delle regioni 2x2 o 3x3. Nella parte finale della rete, vengono tipicamente aggiunti strati interamente connessi (come nelle reti neurali standard), prima di procedere alla classificazione. Questi sono solo gli elementi di base delle reti convolutive; vedremo alcuni concetti più avanzati, necessari a costruire reti con numerosi strati nascosti, in un prossimo tutorial.\n",
    "\n",
    "Va notato da subito come, nel caso delle CNN, l'attivazione di un singolo strato è ora descritta da un tensore a *quattro* dimensioni, in quanto l'uscita di ciascun filtro è a sua volta bidimensionale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esempio di classificazione su immagini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come esempio di problema di classificazione di immagini, utilizziamo il dataset [**Labeled faces in the wild**](http://vis-www.cs.umass.edu/lfw/), una collezione annotata di immagini di numerose celebrità.\n",
    "\n",
    "\n",
    "<code>scikit-learn</code> mette a disposizione una funzione per scaricare il dataset, oltre 200 MB di dati in questa versione:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nell'esempio prima, abbiamo scelto di scaricare solo le immagini di persone di cui abbiamo (almeno) 70 esempi, le quali sono soltanto 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ariel Sharon', 'Colin Powell', 'Donald Rumsfeld', 'George W Bush',\n",
       "       'Gerhard Schroeder', 'Hugo Chavez', 'Tony Blair'], \n",
       "      dtype='<U17')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfw_people.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per semplicità, consideriamo qui un problema di classificazione binaria per distinguire fra le foto di Colin Powell (236 foto) e le foto di Tony Blair (144 foto):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = (lfw_people.target == 1) | (lfw_people.target == 6)\n",
    "X = lfw_people.images[idx]\n",
    "y = lfw_people.target[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sistemiamo il vettore di target in modo che contenga solo 0 od 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y[y == 6] = 0\n",
    "y = y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per comodità di TF, aggiungiamo una dimensione alla matrice di immagini, che rappresenta il singolo canale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggiungendo un parametro <code>color=True</code> alla funzione <code>fetch_lfw_people</code> potremmo scaricare i tre canali RGB invece di un singolo canale in scala di grigi. Di tutte le immagini teniamo da parte un 20% per andare a testare la nostra rete neurale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "(X_trn, X_tst, y_trn, y_tst) = model_selection.train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo un esempio di immagine di training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xaa37c88>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMYAAAD8CAYAAAAsetuWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFSORnKNv++MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa967ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X[1,:,:, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come si può vedere, ciascuna immagine è 50x37, in bianco e nero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 37, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per finire, rappresentiamo i pixel in [0,1], invece che in [0, 255]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Costruiamo la nostra rete convolutiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come nello scorso tutorial, cominciamo definendo i nostri placeholder di input e di output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "X_tf = tf.placeholder(tf.float32, [None, 50, 37, 1], name='input')\n",
    "y_tf = tf.placeholder(tf.float32, [None, 1], name='target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al posto di definire manualmente tutte le variabili e le operazioni della rete, iniziamo ad utilizzare gli strati già definiti nel modulo <code>layers</code>:\n",
    "https://www.tensorflow.org/api_docs/python/tf/layers/.\n",
    "\n",
    "Va sottolineato da subito come alcuni di questi strati si appoggiano interiormente a funzioni più semplici definite nel modulo <code>nn</code>, come lo strato per la convoluzione 2D (<code>conv2D</code>):\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/layers/conv2d<br />\n",
    "https://www.tensorflow.org/api_docs/python/tf/nn/conv2d\n",
    "\n",
    "Questa duplicazione di classi non deve però confondere, in quanto è possibile usare in maniera equivalente ciascuno dei due; le funzioni in <code>nn</code> hanno in genere meno parametri e meno flessibilità, e sono preferibili quando questa flessibilità non è richiesta.\n",
    "\n",
    "Per uniformità, in questo tutorial useremo solo le funzioni definite nel modulo <code>layers</code>. La nostra rete sarà così composta:\n",
    "\n",
    "* Uno strato convolutivo, con 64 filtri 5x5.\n",
    "* Uno strato di pooling 2x2.\n",
    "* Un secondo strato convolutivo, con 32 filtri 5x5.\n",
    "* Un secondo strato di pooling 2x2.\n",
    "* Uno strato interamente connesso con 20 neuroni.\n",
    "* Un neurone di uscita con la classe desiderata.\n",
    "\n",
    "Questa non è ovviamente l'unica scelta, né tantomeno la migliore, il che richiederebbe un'ottimizzazione più completa di tutto il design della rete (si veda ad esempio [questo articolo](https://arxiv.org/abs/1611.00847)). Questo genere di alternanza di strati convolutivi e pooling, di dimensioni sempre più piccole, e seguito da strati densamente connessi è però tipico nella maggior parte delle applicazioni con reti non molto grandi. Considereremo il design di reti più complesse e la loro ottimizzazione in tutorial successivi; va detto da subito, comunque, che spesso questa fase di costruzione è più un unirsi di esperienza ed 'arte', piuttosto che il susseguirsi di regole precise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniziamo definendo il primo strato convolutivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv1 = tf.layers.conv2d(X_tf, 64, (5,5), activation=tf.nn.relu, name='conv1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andiamo a valutare la dimensione del tensore di uscita:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(46), Dimension(33), Dimension(64)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come sempre, la prima dimensione rappresenta un mini-batch di attivazioni. Il resto del tensore è quindi costituito da 64 filtri, ciascuno 46x33. Si noti la leggera discrepanza con la dimensione delle immagini di ingresso: poiché la convoluzione non è definita sui bordi dell'immagine, perdiamo 2 pixel in ogni dimensione. Possiamo ovviare a questo problema aggiungendo del padding di zeri sui bordi dell'immagine originale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# conv1 = tf.layers.conv2d(X_tf, 64, (5,5), padding='same', name='conv1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuiamo aggiungendo lo strato di pooling, questa volta considerando il padding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pool1 = tf.layers.max_pooling2d(conv1, (2,2), (2,2), padding='same', name='pool1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il terzo parametro rappresenta lo **stride**, ovvero ogni quanti pixel calcoliamo un risultato. Con questa configurazione, abbiamo effettivamente dimezzato la dimensione dei tensori: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(23), Dimension(17), Dimension(64)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuiamo con tutti gli strati rimanenti:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv2 = tf.layers.conv2d(pool1, 32, (5,5), activation=tf.nn.relu, padding='same', name='conv2')\n",
    "pool2 = tf.layers.max_pooling2d(conv2, (2,2), (2,2), padding='same', name='pool2')\n",
    "dense = tf.layers.dense(tf.reshape(pool2, [-1, 12*9*32]), 20, activation=tf.nn.relu, name='dense')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si noti come, per applicare lo strato interamente connesso, è necessario eseguire un reshape del tensore di ingresso, in modo che ogni input sia 1D. Concludiamo con l'ultimo strato con un'attivazione sigmoide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = tf.layers.dense(dense, 1, activation=None, name='output')\n",
    "output_sigmoid = tf.nn.sigmoid(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allenare la rete convolutiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fase di allenamento è sostanzialmente uguale allo scorso tutorial. In particolare, definiamo una funzione per estrarre mini-batch casuali dalle nostre immagini di training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(X, y, batchsize):\n",
    "    indices = np.arange(len(X))\n",
    "    np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(X) - batchsize + 1, batchsize):\n",
    "        excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        yield X[excerpt], y[excerpt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo una funzione costo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y_tf, logits=output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inizializziamo un algoritmo di ottimizzazione:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.AdagradOptimizer(learning_rate=0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per valutare l'accuratezza, definiamo una funzione ausiliaria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(y_tf, tf.round(output_sigmoid)), tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creiamo una sessione ed inizializziamo tutte le variabili:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo una dimensione del mini-batch ed un numero di epoche:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poiché il training potrebbe essere più lento dello scorso tutorial, installiamo un modulo per visualizzare una semplice barra di progresso:\n",
    "\n",
    "<code>$ pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimizziamo la funzione costo, tenendo traccia dell'accuratezza sul test set ad ogni iterazione:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss is:  6.66727\n",
      "Current loss is:  2.1861\n",
      "Current loss is:  0.551535\n",
      "Current loss is:  0.426429\n",
      "Current loss is:  0.319568\n",
      "Current loss is:  0.24247\n",
      "Current loss is:  0.186849\n",
      "Current loss is:  0.240138\n",
      "Current loss is:  0.138694\n",
      "Current loss is:  0.0947196\n",
      "Current loss is:  0.0959329\n",
      "Current loss is:  0.055467\n",
      "Current loss is:  0.0548337\n",
      "Current loss is:  0.0352569\n",
      "Current loss is:  0.0356559\n",
      "Current loss is:  0.0200885\n",
      "Current loss is:  0.0174607\n",
      "Current loss is:  0.016162\n",
      "Current loss is:  0.0123268\n",
      "Current loss is:  0.010254\n",
      "Current loss is:  0.00883825\n",
      "Current loss is:  0.00784905\n",
      "Current loss is:  0.0073456\n",
      "Current loss is:  0.00730925\n",
      "Current loss is:  0.00553962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, tqdm\n",
    "accuracy_history = np.zeros(epochs)\n",
    "for i in tqdm.tqdm_notebook(range(epochs)):\n",
    "    accuracy_history[i] = sess.run(accuracy, feed_dict={X_tf: X_tst, y_tf: y_tst})\n",
    "    print('Current loss is: ', sess.run(loss, feed_dict={X_tf: X_trn, y_tf: y_trn}))\n",
    "    for xs, ys in iterate_minibatches(X_trn, y_trn, batch_size):\n",
    "        sess.run(train_step, feed_dict={X_tf: xs, y_tf: ys})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizziamo l'accuratezza media sul test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAEKCAYAAADNSVhkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xccf8e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.semilogy(accuracy_history)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Test error')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come si vede, l'accuratezza raggiunge rapidamente il 100%. Se continuassimo il training, o con un dataset meno pulito, ci vorrebbe poco prima di passare però in un regime di **overfitting**. Questo non deve stupire: come detto all'inizio, la flessibilità delle reti neurali è enorme, ed il nostro dataset in questo e molti altri casi è ben lungi dall'essere perfetto. L'overfitting e le tecniche per affrontarlo nelle CNN saranno uno dei protagonisti di un prossimo tutorial.\n",
    "\n",
    "Prima di rispondere (in parte) a tutte queste domande, ci occuperemo del tema essenziale di **visualizzare** quanto avviene in fase di allenamento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
